{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy.fft as fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 100\n",
    "\n",
    "num_alphas = 10\n",
    "alphlowlim = 0.0\n",
    "alphhighlim = 0.9\n",
    "num_ds = 50\n",
    "dlowlim = 0.0\n",
    "dhighlim = 4.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n",
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7\n",
      " 1.8 1.9 2.  2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.  3.1 3.2 3.3 3.4 3.5\n",
      " 3.6 3.7 3.8 3.9 4.  4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9]\n",
      "shape of alpha_vals : (10,)\n",
      "shape of d_vals : (50,)\n"
     ]
    }
   ],
   "source": [
    "alpha_vals = np.linspace(alphlowlim, alphhighlim, num_alphas)\n",
    "print(alpha_vals)\n",
    "alpha_vals[0] = 1e-10 # set alpha=0 to a small value\n",
    "\n",
    "d_vals = np.linspace(dlowlim, dhighlim, num_ds)\n",
    "print(d_vals)\n",
    "d_vals[0] = 1e-10 # set d=0 to a small value\n",
    "\n",
    "\n",
    "r_vals = np.linspace(0.0, 10.0, 501)\n",
    "r_vals = r_vals[:-1]\n",
    "r_vals[0] = 1e-10 # set r=0 to a small value\n",
    "\n",
    "k_vals = fft.fftfreq(r_vals.shape[0], d=r_vals[1]-r_vals[0])\n",
    "\n",
    "# convert to tensor\n",
    "r_vals = torch.from_numpy(r_vals).float().to(device)\n",
    "\n",
    "\n",
    "# print the shape of the data\n",
    "print(f\"shape of alpha_vals : {alpha_vals.shape}\")\n",
    "print(f\"shape of d_vals : {d_vals.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess for P_alpha_d\n",
    "P_alpha_d = np.zeros((num_frames, num_alphas, num_ds))\n",
    "for i in range(num_frames):\n",
    "    P_alpha_d[i, 0, 0] = 1.0\n",
    "\n",
    "\n",
    "alpha0 = 0.2\n",
    "d0 = 2.5\n",
    "# for i in range(num_alphas):\n",
    "#     for j in range(num_ds):\n",
    "#         P_alpha_d[:, i, j] = np.exp(-((alpha_vals[i] - alpha0)**2 + (d_vals[j] - d0)**2) / 0.1)\n",
    "\n",
    "# # normalize P_alpha_d\n",
    "# P_alpha_d = P_alpha_d / np.sum(P_alpha_d, axis=(1, 2))[:, None, None]\n",
    "\n",
    "\n",
    "# convert to tensor\n",
    "alpha_vals = torch.from_numpy(alpha_vals).float().to(device)\n",
    "# convert to tensor\n",
    "d_vals = torch.from_numpy(d_vals).float().to(device)\n",
    "# convert to tensor\n",
    "k_vals = torch.from_numpy(k_vals).float().to(device)\n",
    "\n",
    "# convert P_alpha_d to torch tensor\n",
    "P_alpha_d = torch.tensor(P_alpha_d, dtype=torch.float32, device=device, requires_grad=True)\n",
    "# restrict P_alpha_d to be positive while training\n",
    "# P_alpha_d = torch.clamp(P_alpha_d, min=0.0)\n",
    "# print(P_alpha_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_plt(P_alpha_d, i=0):\n",
    "    \"\"\"\n",
    "    Visualise P_alpha_d as a countour plot using contourf\n",
    "    \"\"\"\n",
    "    # plot\n",
    "    # rescale the y axis to be in the range of 0 to 2\n",
    "    # rescale the x axis to be in the range of 0 to 1000\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    x = np.linspace(dlowlim, dhighlim, num_ds)\n",
    "    y = np.linspace(alphlowlim, alphhighlim, num_alphas)\n",
    "    plt.contourf(x, y, P_alpha_d[i], 20, cmap='RdGy')\n",
    "    plt.xlabel('d')\n",
    "    plt.ylabel('alpha')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize P_alpha_d inital in subplots\n",
    "# for i in range(num_frames):\n",
    "#     contour_plt(P_alpha_d, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of u : (100, 500)\n",
      "shape of u : torch.Size([100, 500])\n"
     ]
    }
   ],
   "source": [
    "# load u_pred\n",
    "u = np.loadtxt(\"u.txt\")\n",
    "print(f\"shape of u : {u.shape}\")\n",
    "# print(u_pred)\n",
    "# convert to torch tensor\n",
    "u = torch.tensor(u, dtype=torch.float32, device=device)\n",
    "print(f\"shape of u : {u.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Z : (10, 50, 100, 500)\n",
      "shape of Z : torch.Size([10, 50, 100, 500])\n"
     ]
    }
   ],
   "source": [
    "# load Z\n",
    "Z = np.load(\"Z.npy\")\n",
    "print(f\"shape of Z : {Z.shape}\")\n",
    "# convert Z to torch tensor\n",
    "Z = torch.from_numpy(Z).float().to(device)\n",
    "# print shape of Z\n",
    "print(f\"shape of Z : {Z.shape}\")\n",
    "# print(Z)\n",
    "# normalize Z to have integral of Z over r equal to 1\n",
    "# Z = Z / np.sum(Z * (r_vals[1]-r_vals[0]))\n",
    "# print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_u_pred(P_alpha_d, Z, alpha_vals, d_vals):\n",
    "    \"\"\"\n",
    "    Given P_alpha_d, Z, alpha_vals, d_vals, return u_pred\n",
    "    \"\"\"\n",
    "    # initialize u_pred\n",
    "    u_pred = torch.zeros((num_frames, len(r_vals)))\n",
    "    # move u_pred to device\n",
    "    u_pred = u_pred.to(device)\n",
    "\n",
    "    for i in range(u_pred.shape[0]):\n",
    "        for j in range(u_pred.shape[1]):\n",
    "            integrand = torch.trapz(P_alpha_d[i] * Z[:, :, i, j], d_vals)\n",
    "            u_pred[i, j] = torch.trapz(integrand, alpha_vals)\n",
    "\n",
    "    # normalize u_pred\n",
    "    # u_pred = u_pred / (u_pred.sum(dim=1, keepdim=True) + 1e-9)\n",
    "    # u_pred = u_pred / (torch.trapz(u_pred, k_vals, dim=1, keepdim=True) + 1e-9)\n",
    "    norm = (torch.trapz(u_pred, k_vals, dim=1))\n",
    "\n",
    "    u_pred = u_pred / norm[:, None]\n",
    "\n",
    "\n",
    "    return u_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual loss function\n",
    "def loss_function(P_alpha_d, u, Z, alpha_vals, d_vals):\n",
    "    # clamp P_alpha_d to be positive\n",
    "    P_alpha_d.data = P_alpha_d.data.clamp(min=0.0)\n",
    "    # normalize P_alpha_d\n",
    "    norm = (torch.trapz(torch.trapz(P_alpha_d, d_vals, dim=2), alpha_vals, dim=1))\n",
    "    P_alpha_d = P_alpha_d / norm[:, None, None]\n",
    "    # P_alpha_d = P_alpha_d / (torch.trapz(torch.trapz(P_alpha_d, d_vals, dim=2), alpha_vals, dim=1, keepdim=True) + 1e-6)\n",
    "    # P_alpha_d = P_alpha_d / (P_alpha_d.sum(dim=(1,2), keepdim=True))\n",
    "    # P_alpha_d = P_alpha_d / (P_alpha_d.sum(dim=(1,2), keepdim=True) + 1e-6)\n",
    "    # calculate u_pred using double integral\n",
    "    u_pred = give_u_pred(P_alpha_d, Z, alpha_vals, d_vals)\n",
    "    # calculate loss\n",
    "    loss = torch.sum((u_pred - u)**2)\n",
    "    # loss = torch.sum(abs(u_pred - u))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to train the model\n",
    "def train(P_alpha_d, u, Z, alpha_vals, d_vals, num_epochs=100, lr=1e-1):\n",
    "    # define the optimizer\n",
    "    optimizer = torch.optim.Adam([P_alpha_d], lr=lr)\n",
    "    # define the loss function\n",
    "    loss_func = loss_function\n",
    "    # define the loss history\n",
    "    loss_history = []\n",
    "    # train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        # calculate loss\n",
    "        loss = loss_func(P_alpha_d, u, Z, alpha_vals, d_vals)\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # append loss to loss history\n",
    "        loss_history.append(loss.item())\n",
    "        # print loss\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f\"epoch {epoch+1} / {num_epochs} : loss = {loss.item()}\")\n",
    "    # plot loss history\n",
    "    plt.figure()\n",
    "    plt.plot(loss_history)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "\n",
    "    return P_alpha_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 1000 : loss = 5176778.5\n",
      "epoch 2 / 1000 : loss = 5171916.0\n",
      "epoch 3 / 1000 : loss = 5170547.5\n",
      "epoch 4 / 1000 : loss = 5169981.0\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "P_alpha_d = train(P_alpha_d, u, Z, alpha_vals, d_vals, num_epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_alpha_d_cpu = P_alpha_d.cpu().detach().numpy()\n",
    "# normalize P_alpha_d_cpu\n",
    "P_alpha_d_cpu = P_alpha_d_cpu / (P_alpha_d_cpu.sum(axis=(1,2), keepdims=True))\n",
    "print(f\"shape of P_alpha_d_cpu : {P_alpha_d_cpu.shape}\")\n",
    "# save P_alpha_d_cpu\n",
    "np.save(\"P_alpha_d_cpu.npy\", P_alpha_d_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, num_frames, 5):\n",
    "    # copy P_alpha_d to cpu\n",
    "    contour_plt(P_alpha_d_cpu, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_u_pred_np_and_plot(P_alpha_d, Z, alpha_vals, d_vals, r_vals):\n",
    "    \"\"\"\n",
    "    Given P_alpha_d, Z, alpha_vals, d_vals, return u_pred\n",
    "    \"\"\"\n",
    "    # initialize u_pred\n",
    "    u_pred = np.zeros((num_frames, len(r_vals)))\n",
    "\n",
    "    # convert P_alpha_d to numpy array\n",
    "    P_alpha_d = P_alpha_d.cpu().detach().numpy()\n",
    "    Z = Z.cpu().detach().numpy()\n",
    "    alpha_vals = alpha_vals.cpu().detach().numpy()\n",
    "    d_vals = d_vals.cpu().detach().numpy()\n",
    "\n",
    "    for i in range(u_pred.shape[0]):\n",
    "        for j in range(u_pred.shape[1]):\n",
    "            integrand = np.trapz(P_alpha_d[i] * Z[:, :, i, j], d_vals, axis=1)\n",
    "            u_pred[i, j] = np.trapz(integrand, alpha_vals)\n",
    "\n",
    "    # normalize u_pred\n",
    "    u_pred = u_pred / (u_pred.sum(axis=1, keepdims=True) + 1e-6)\n",
    "    # u_pred = u_pred / (u_pred.sum(axis=1, keepdims=True))\n",
    "\n",
    "    # s_vals = np.linspace(0.0, 2*np.pi, 101)\n",
    "    s_vals = np.linspace(0.0, 100, 101)\n",
    "    s_vals[0] = 1e-10\n",
    "    s_vals = s_vals[:-1]\n",
    "\n",
    "    # get the range of k values\n",
    "    # convert r_vals to numpy array\n",
    "    r_vals = r_vals.cpu().detach().numpy()\n",
    "    k_vals = fft.fftfreq(r_vals.shape[0], d=r_vals[1]-r_vals[0])\n",
    "    # k_vals = 2 * np.pi * k_vals\n",
    "    # print(k_vals)\n",
    "    print(f\"shape of k_vals : {k_vals.shape}\")\n",
    "\n",
    "    # visualize u_pred\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(\"u_pred(s, k) for some s values\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"u_pred(s, k)\")\n",
    "    plt.grid()\n",
    "    for i in range(0, s_vals.shape[0], 10):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        plt.plot(k_vals, u_pred[i, :], label=f\"s = {s_vals[i]:.2f}\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce u_pred\n",
    "give_u_pred_np_and_plot(P_alpha_d, Z, alpha_vals, d_vals, r_vals)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
